{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom\n",
    "# Package Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score,\\\n",
    "    accuracy_score, precision_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "\n",
    "#New imports for our Pipeline workflows\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#New imports from imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/original_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State, phone number, intl plan, voice mail plan are objects -- need to encode\n",
    "\n",
    "Account Length - maybe days, how long customer has been with company\n",
    "\n",
    "6 - 18 Usage Stats = number of calls number of minutes and charge for different time categories.\n",
    "\n",
    "19 - # of customer service calls\n",
    "\n",
    "Possible Churn Indicators:\n",
    "\n",
    "- By State?\n",
    "- High Customer Service Contact = high churn?\n",
    "- Low Calls/Low minutes = higher churn?\n",
    "- Can we identify a customer profile that is likely to churn for targeted marketing/incentives?\n",
    "- Drop Phone number -- basically a unique identifer for every customer, not likely to help in predictions\n",
    "\n",
    "- Location\n",
    "    - State/Area Code\n",
    "    \n",
    "- Duration\n",
    "    - Account Length\n",
    "    \n",
    "- Plan Types\n",
    "    - Intl / Voicemail\n",
    "    \n",
    "- Usage Stats\n",
    "    - minutes\n",
    "    - num calls\n",
    "    - charges\n",
    "    - customer service calls\n",
    "\n",
    "Drop Phone number\n",
    "\n",
    "Encoding Process:\n",
    "    - voicemail plan = labelencoder 1/0\n",
    "    - international plan = 1/0\n",
    "    - state - onehot encoding\n",
    "\n",
    "Scale Numerical Features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop phone number from the data set--in this context, it acts as a unique identifier with little meaningful context.\n",
    "df.drop('phone number', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2233 entries, 2360 to 3174\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   2233 non-null   object \n",
      " 1   account length          2233 non-null   int64  \n",
      " 2   area code               2233 non-null   int64  \n",
      " 3   international plan      2233 non-null   object \n",
      " 4   voice mail plan         2233 non-null   object \n",
      " 5   number vmail messages   2233 non-null   int64  \n",
      " 6   total day minutes       2233 non-null   float64\n",
      " 7   total day calls         2233 non-null   int64  \n",
      " 8   total day charge        2233 non-null   float64\n",
      " 9   total eve minutes       2233 non-null   float64\n",
      " 10  total eve calls         2233 non-null   int64  \n",
      " 11  total eve charge        2233 non-null   float64\n",
      " 12  total night minutes     2233 non-null   float64\n",
      " 13  total night calls       2233 non-null   int64  \n",
      " 14  total night charge      2233 non-null   float64\n",
      " 15  total intl minutes      2233 non-null   float64\n",
      " 16  total intl calls        2233 non-null   int64  \n",
      " 17  total intl charge       2233 non-null   float64\n",
      " 18  customer service calls  2233 non-null   int64  \n",
      "dtypes: float64(8), int64(8), object(3)\n",
      "memory usage: 348.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     1621\n",
       "yes     612\n",
       "Name: voice mail plan, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['voice mail plan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define datatype of columns\n",
    "num_cols = [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "cat_cols = [0, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMBLearn Pipeline for SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to identify and select columns based on the datatype stored in that column.\n",
    "def get_numeric(df):\n",
    "    return df.select_dtypes(include=['float', 'int'])\n",
    "\n",
    "def get_categorical(df):\n",
    "    return df.select_dtypes(include=['bool', 'object'])\n",
    "\n",
    "# Create transformer objects using our get functions\n",
    "GetNumeric = FunctionTransformer(get_numeric)\n",
    "GetCategories = FunctionTransformer(get_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpipelines to select and scale our numeric data / select and one-hot encode our categorical data.\n",
    "subpipe_num = Pipeline(steps=[('num', GetNumeric),\n",
    "                        ('ss', StandardScaler())])\n",
    " \n",
    "subpipe_ohe = Pipeline(steps=[('cat', GetCategories), \n",
    "                              ('ohe', OneHotEncoder(drop='if_binary', sparse=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numeric and categorical columns.\n",
    "num_cols = [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "cat_cols = [0, 3, 4]\n",
    "\n",
    "# Create ColumnTransformer object that contains our subpipes for column transformation\n",
    "CT = ColumnTransformer(transformers=[\n",
    "                                    ('subpipe_num', subpipe_num, num_cols),\n",
    "                                    ('subpipe_ohe', subpipe_ohe, cat_cols)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template, any model can be appended to the end.\n",
    "template_model_pipe = ImPipeline(steps=[\n",
    "                                        ('ct', CT),\n",
    "                                        ('sm', sm),\n",
    "                                        ('dc', DummyClassifier(strategy='most_frequent', random_state=42))\n",
    "                                       ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8553515450067174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_model_pipe.fit(X_train, y_train)\n",
    "template_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = ImPipeline(steps=[\n",
    "                                        ('ct', CT),\n",
    "                                        ('sm', sm),\n",
    "                                        ('dt', DecisionTreeClassifier(random_state=42, min_samples_leaf=2))\n",
    "                                       ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num',\n",
       "                                                                   FunctionTransformer(func=<function get_numeric at 0x7fe0680a1f70>)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [1, 2, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                                   12, 13, 14, 15, 16, 17,\n",
       "                                                   18]),\n",
       "                                                 ('subpipe_ohe',\n",
       "                                                  Pipeline(steps=[('cat',\n",
       "                                                                   FunctionTransformer(func=<function get_categorical at 0x7fe0a825e8b0>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [0, 3, 4])])),\n",
       "                ('sm', SMOTE(random_state=42, sampling_strategy=0.75)),\n",
       "                ('dt',\n",
       "                 DecisionTreeClassifier(min_samples_leaf=2, random_state=42))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.95      0.95       940\n",
      "        True       0.72      0.73      0.73       160\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.84      0.84      0.84      1100\n",
      "weighted avg       0.92      0.92      0.92      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_y_hat = dt_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, dt_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=Pipeline(steps=[('ct',\n",
      "                 ColumnTransformer(transformers=[('subpipe_num',\n",
      "                                                  Pipeline(steps=[('num',\n",
      "                                                                   FunctionTransformer(func=<function get_numeric at 0x7fe0680a1f70>)),\n",
      "                                                                  ('ss',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  [1, 2, 5, 6, 7, 8, 9, 10, 11,\n",
      "                                                   12, 13, 14, 15, 16, 17,\n",
      "                                                   18]),\n",
      "                                                 ('subpipe_ohe',\n",
      "                                                  Pipeline(steps=[('cat',\n",
      "                                                                   FunctionTransformer(func=<function get_categorical at 0x7fe0a825e8b0>)),\n",
      "                                                                  ('ohe',\n",
      "                                                                   OneHotEncoder(drop='if_binary',\n",
      "                                                                                 sparse=False))]),\n",
      "                                                  [0, 3, 4])])),\n",
      "                ('sm', SMOTE(random_state=42, sampling_strategy=0.75)),\n",
      "                ('dt',\n",
      "                 DecisionTreeClassifier(min_samples_leaf=2, random_state=42))]) as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7267080745341615"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, dt_y_hat, dt_pipeline, zero_division=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                'dt__criterion' : ['gini', 'entropy'],    #entropy\n",
    "                'dt__min_samples_leaf' : [3, 4, 5, 6]  # 5 min samples\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=dt_pipeline, param_grid=params, n_jobs=-4, verbose=3, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  18 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num',\n",
       "                                                                                          FunctionTransformer(func=<function get_numeric at 0x7fe0680a1f70>)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [1, 2,\n",
       "                                                                          5, 6,\n",
       "                                                                          7, 8,\n",
       "                                                                          9, 10,\n",
       "                                                                          11,\n",
       "                                                                          12,\n",
       "                                                                          13,\n",
       "                                                                          14,\n",
       "                                                                          15,\n",
       "                                                                          16,\n",
       "                                                                          17,\n",
       "                                                                          18]),\n",
       "                                                                        ('subpipe_ohe',\n",
       "                                                                         Pipeline(steps=[('cat',\n",
       "                                                                                          FunctionTransformer(func=<function get_categorical at 0x7fe0a825e8b0>)),\n",
       "                                                                                         ('ohe',\n",
       "                                                                                          OneHotEncoder(drop='if_binary',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [0, 3,\n",
       "                                                                          4])])),\n",
       "                                       ('sm',\n",
       "                                        SMOTE(random_state=42,\n",
       "                                              sampling_strategy=0.75)),\n",
       "                                       ('dt',\n",
       "                                        DecisionTreeClassifier(min_samples_leaf=2,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-4,\n",
       "             param_grid={'dt__criterion': ['gini', 'entropy'],\n",
       "                         'dt__min_samples_leaf': [1, 2, 3, 4, 5]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'gini', 'dt__min_samples_leaf': 4}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = ImPipeline(steps=[\n",
    "                                        ('ct', CT),\n",
    "                                        ('sm', sm),\n",
    "                                        ('knn', KNeighborsClassifier())\n",
    "                                       ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num',\n",
       "                                                                   FunctionTransformer(func=<function get_numeric at 0x7fe1fa8eae50>)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [1, 2, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                                   12, 13, 14, 15, 16, 17,\n",
       "                                                   18]),\n",
       "                                                 ('subpipe_ohe',\n",
       "                                                  Pipeline(steps=[('cat',\n",
       "                                                                   FunctionTransformer(func=<function get_categorical at 0x7fe1fa8eaca0>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [0, 3, 4])])),\n",
       "                ('sm',\n",
       "                 SMOTENC(categorical_features=[0, 3, 4], random_state=42)),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.77      0.85       940\n",
      "        True       0.34      0.70      0.46       160\n",
      "\n",
      "    accuracy                           0.76      1100\n",
      "   macro avg       0.64      0.73      0.65      1100\n",
      "weighted avg       0.85      0.76      0.79      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_y_hat = knn_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, knn_y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = ImPipeline(steps=[\n",
    "                                        ('ct', CT),\n",
    "                                        ('sm', sm),\n",
    "                                        ('lr', LogisticRegression(random_state=42))\n",
    "                                       ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num',\n",
       "                                                                   FunctionTransformer(func=<function get_numeric at 0x7fe1fa8eae50>)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [1, 2, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                                   12, 13, 14, 15, 16, 17,\n",
       "                                                   18]),\n",
       "                                                 ('subpipe_ohe',\n",
       "                                                  Pipeline(steps=[('cat',\n",
       "                                                                   FunctionTransformer(func=<function get_categorical at 0x7fe1fa8eaca0>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [0, 3, 4])])),\n",
       "                ('sm',\n",
       "                 SMOTENC(categorical_features=[0, 3, 4], random_state=42)),\n",
       "                ('lr', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.78      0.86       940\n",
      "        True       0.37      0.74      0.49       160\n",
      "\n",
      "    accuracy                           0.77      1100\n",
      "   macro avg       0.66      0.76      0.67      1100\n",
      "weighted avg       0.86      0.77      0.80      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_y_hat = lr_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, lr_y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = ImPipeline(steps=[\n",
    "                                        ('ct', CT),\n",
    "               #                         ('sm', sm),\n",
    "                                        ('rf', RandomForestClassifier(random_state=42))\n",
    "                                       ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num',\n",
       "                                                                   FunctionTransformer(func=<function get_numeric at 0x7fb7bc890790>)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [1, 2, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                                   12, 13, 14, 15, 16, 17,\n",
       "                                                   18]),\n",
       "                                                 ('subpipe_ohe',\n",
       "                                                  Pipeline(steps=[('cat',\n",
       "                                                                   FunctionTransformer(func=<function get_categorical at 0x7fb7bc890b80>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(sparse=False))]),\n",
       "                                                  [0, 3, 4])])),\n",
       "                ('rf', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      1.00      0.97       940\n",
      "        True       0.97      0.61      0.75       160\n",
      "\n",
      "    accuracy                           0.94      1100\n",
      "   macro avg       0.95      0.80      0.86      1100\n",
      "weighted avg       0.94      0.94      0.94      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_y_hat = rf_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, rf_y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to identify and select columns based on the datatype stored in that column.\n",
    "def get_numeric(df):\n",
    "    return df.select_dtypes(include=['float', 'int'])\n",
    "\n",
    "def get_categorical(df):\n",
    "    return df.select_dtypes(include=['bool', 'object'])\n",
    "\n",
    "# Create transformer objects using our get functions\n",
    "GetNumeric = FunctionTransformer(get_numeric)\n",
    "GetCategories = FunctionTransformer(get_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpipelines to select and scale our numeric data / select and one-hot encode our categorical data.\n",
    "subpipe_num = Pipeline(steps=[('num', GetNumeric),\n",
    "                        ('ss', StandardScaler())])\n",
    " \n",
    "subpipe_ohe = Pipeline(steps=[('cat', GetCategories), \n",
    "                              ('ohe', OneHotEncoder(sparse=False))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numeric and categorical columns.\n",
    "num_cols = [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "cat_cols = [0, 3, 4]\n",
    "\n",
    "# Create ColumnTransformer object that contains our subpipes for column transformation\n",
    "CT = ColumnTransformer(transformers=[\n",
    "                                    ('subpipe_num', subpipe_num, num_cols),\n",
    "                                    ('subpipe_ohe', subpipe_ohe, cat_cols)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DummyRegressor Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize DummyClassifier as our first model, guessing the most frequent value of y for all ys.\n",
    "dummy_model_pipe = Pipeline(steps=[('ct', CT),\n",
    "                                   ('dc', DummyClassifier(strategy='most_frequent', random_state=42))\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit dummy model on our training data.\n",
    "dummy_model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=dummy_model_pipe.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
